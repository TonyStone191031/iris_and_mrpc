{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc3ffe9-e8b2-4d2f-9e10-b87c81b6044b",
   "metadata": {},
   "source": [
    "# 一、读取把csv训练集转换成Alpaca json格式的llm训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6014dda-ffe5-49f2-8ec4-8b26fa2e2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ebc827-4b00-4592-88fd-ccdaa784efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/msr_paraphrase_train.tsv',sep='\\t',on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c863817-c098-4f33-bbba-64f412da5929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>1</td>\n",
       "      <td>1620264</td>\n",
       "      <td>1620507</td>\n",
       "      <td>At this point , Mr. Brando announced : ' Some...</td>\n",
       "      <td>Brando said that \" somebody ought to put a bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>0</td>\n",
       "      <td>1848001</td>\n",
       "      <td>1848224</td>\n",
       "      <td>Martin , 58 , will be freed today after servin...</td>\n",
       "      <td>Martin served two thirds of a five-year senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>1</td>\n",
       "      <td>747160</td>\n",
       "      <td>747144</td>\n",
       "      <td>We have concluded that the outlook for price ...</td>\n",
       "      <td>In a statement , the ECB said the outlook for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>1</td>\n",
       "      <td>2539933</td>\n",
       "      <td>2539850</td>\n",
       "      <td>The notification was first reported Friday by ...</td>\n",
       "      <td>MSNBC.com first reported the CIA request on Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>0</td>\n",
       "      <td>453575</td>\n",
       "      <td>453448</td>\n",
       "      <td>The 30-year bond US30YT = RR rose 22 / 32 for ...</td>\n",
       "      <td>The 30-year bond US30YT = RR grew 1-3 / 32 for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Quality    #1 ID    #2 ID  \\\n",
       "3933        1  1620264  1620507   \n",
       "3934        0  1848001  1848224   \n",
       "3935        1   747160   747144   \n",
       "3936        1  2539933  2539850   \n",
       "3937        0   453575   453448   \n",
       "\n",
       "                                              #1 String  \\\n",
       "3933   At this point , Mr. Brando announced : ' Some...   \n",
       "3934  Martin , 58 , will be freed today after servin...   \n",
       "3935   We have concluded that the outlook for price ...   \n",
       "3936  The notification was first reported Friday by ...   \n",
       "3937  The 30-year bond US30YT = RR rose 22 / 32 for ...   \n",
       "\n",
       "                                              #2 String  \n",
       "3933  Brando said that \" somebody ought to put a bul...  \n",
       "3934  Martin served two thirds of a five-year senten...  \n",
       "3935  In a statement , the ECB said the outlook for ...  \n",
       "3936  MSNBC.com first reported the CIA request on Fr...  \n",
       "3937  The 30-year bond US30YT = RR grew 1-3 / 32 for...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7d76f4-1eb9-4f5d-b6f8-0fc09ba2ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一个指令\n",
    "instruction=\"判断两个句子在语义上是否等同。如果等价，则输出 “1”；如果不等价，则输出 “0”。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31761bfd-2b05-4948-9923-524c7148aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空列表来存储转换后的数据\n",
    "alpaca_data = []\n",
    "for index, row in df.iterrows():\n",
    "    # 创建一个字典来存储当前行的数据\n",
    "    data_point = {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": f\"句子 1: {row['#1 String']}\\n句子 2: {row['#2 String']}\",\n",
    "        \"output\": str(row['Quality'])\n",
    "    }\n",
    "    # 将字典添加到列表中\n",
    "    alpaca_data.append(data_point)\n",
    "\n",
    "# 将列表转换为JSON字符串\n",
    "alpaca_json = json.dumps(alpaca_data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4c9b36-9bc9-4b26-a181-253e1dc43cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '判断两个句子在语义上是否等同。如果等价，则输出 “1”；如果不等价，则输出 “0”。',\n",
       " 'input': \"句子 1: The 30-year bond US30YT = RR rose 22 / 32 for a yield of 4.31 percent , versus 4.35 percent at Wednesday 's close .\\n句子 2: The 30-year bond US30YT = RR grew 1-3 / 32 for a yield of 4.30 percent , down from 4.35 percent late Wednesday .\",\n",
       " 'output': '0'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56156582-d755-473f-82f9-2901d1b00926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存到文件\n",
    "with open('./output/MRPC_train_data.json', 'w') as f:\n",
    "    f.write(alpaca_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646e767-d217-4a09-8b8a-9f53b0e0d296",
   "metadata": {},
   "source": [
    "# 二 编辑llamafactory的dataset.info  \n",
    "> `LLama-factory/data/dataset_info.json`\n",
    "* 将/output/MRPC_train_data.json文件复制到llamafactory的data目录下\n",
    "> 修改 LLaMaFactory/data/dataset_info.json\n",
    "```json\n",
    "{\n",
    "  \"MRPC_train_data\":{\n",
    "     \"file_name\": \"MRPC_train_data.json\"\n",
    "  }, \n",
    "  \"identity\": {\n",
    "    \"file_name\": \"identity.json\"\n",
    "  ......\n",
    "```\n",
    "将llm_train_data.json 记录添加到配置信息中\n",
    "\n",
    "<img src=\"res/1.png\" alt=\"Alt Text\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e3059-5054-453a-bccd-be82e288a747",
   "metadata": {},
   "source": [
    "# 三 使用Llamafacotry 微调\n",
    "** 方式1 ** 通过平台提供的 Llamafactory 界面训练\n",
    "\n",
    "<img src=\"res/2.jpg\" alt=\"Alt Text\" width=\"600\" height=\"400\">\n",
    "\n",
    "* 进入界面后，选择模型，填写模型路径，选择训练集\n",
    "  <img src=\"res/3.jpg\" alt=\"Alt Text\" width=\"800\" height=\"400\">\n",
    "\n",
    "* 根据您的微调经验，调整相关参数，执行训练\n",
    "\n",
    "   <img src=\"res/4.jpg\" alt=\"Alt Text\" width=\"800\" height=\"400\">\n",
    "\n",
    "* 注意, 您需要将ui中生成的脚本复制到output/目录下的train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbe73a-3fa4-4dad-86e4-6a07c74450a7",
   "metadata": {},
   "source": [
    "** 方式2 ** 直接在命令行中执行\n",
    "* 新建 jupyter 终端 \n",
    "* 进入 `/root/dg/LLaMA-Factory` 目录\n",
    "* 命令行下启动微调，例如：\n",
    "```bash\n",
    "llamafactory-cli train \\\n",
    "    --stage sft \\\n",
    "    --do_train True \\\n",
    "    --model_name_or_path /home/public/data/Model/Qwen1.5-1.8B-Chat \\\n",
    "    --preprocessing_num_workers 16 \\\n",
    "    --finetuning_type lora \\\n",
    "    --template qwen \\\n",
    "    --flash_attn auto \\\n",
    "    --dataset_dir data \\\n",
    "    --dataset MRPC_train_data \\\n",
    "    --cutoff_len 1024 \\\n",
    "    --learning_rate 5e-05 \\\n",
    "    --num_train_epochs 3.0 \\\n",
    "    --max_samples 100000 \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --max_grad_norm 1.0 \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 100 \\\n",
    "    --warmup_steps 0 \\\n",
    "    --packing False \\\n",
    "    --report_to none \\\n",
    "    --output_dir saves/Qwen1.5-1.8B-Chat/lora/test_train1 \\\n",
    "    --bf16 True \\\n",
    "    --plot_loss True \\\n",
    "    --ddp_timeout 180000000 \\\n",
    "    --optim adamw_torch \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0 \\\n",
    "    --lora_target all\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51800687-0fd6-451a-9e79-20f6ed8838ed",
   "metadata": {},
   "source": [
    "# 四 使用transformers拉起模型\n",
    "> 需要注意这里我们使用国产算力卡 华为的ascend910b，所以需要引入 torch_npu 库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecd7e16d-1d37-4e3c-92bb-93d4d1851874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import torch_npu\n",
    "from peft import PeftModel,LoraConfig,TaskType\n",
    "\n",
    "device=torch.npu.is_available()\n",
    "\n",
    "model_path = '/home/public/data/Model/Qwen1.5-1.8B-Chat'\n",
    "lora_path = '/root/dg/LLaMA-Factory/saves/Qwen1.5-1.8B-Chat/lora/test_train1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0509d841-6ea5-4a18-85b4-3c03033587e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里的参数要和训练界面或命令下的参数一致\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False, # 训练模式\n",
    "    r=8, # Lora 秩\n",
    "    lora_alpha=16, # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.# Dropout 比例\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31591bc6-2883-443a-b2df-149894c78f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 加载模型 这里我们使用的华为ascend 910B,所device_map=\"npu\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"npu\",torch_dtype=torch.bfloat16)\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65c1603d-6f6c-421b-8130-f9018560be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型所在的device: npu:0\n"
     ]
    }
   ],
   "source": [
    "device = next(model.parameters()).device\n",
    "print(\"模型所在的device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88616c-1d34-45d8-96b7-4d41d370e641",
   "metadata": {},
   "source": [
    "# 读取测试集推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99fba43b-33ee-4c16-9db3-efdd749a482f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0</td>\n",
       "      <td>2685984</td>\n",
       "      <td>2686122</td>\n",
       "      <td>After Hughes refused to rehire Hernandez , he ...</td>\n",
       "      <td>Hernandez filed an Equal Employment Opportunit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>0</td>\n",
       "      <td>339215</td>\n",
       "      <td>339172</td>\n",
       "      <td>There are 103 Democrats in the Assembly and 47...</td>\n",
       "      <td>Democrats dominate the Assembly while Republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>0</td>\n",
       "      <td>2996850</td>\n",
       "      <td>2996734</td>\n",
       "      <td>Bethany Hamilton remained in stable condition ...</td>\n",
       "      <td>Bethany , who remained in stable condition aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1</td>\n",
       "      <td>2095781</td>\n",
       "      <td>2095812</td>\n",
       "      <td>Last week the power station ’ s US owners , AE...</td>\n",
       "      <td>The news comes after Drax 's American owner , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1</td>\n",
       "      <td>2136244</td>\n",
       "      <td>2136052</td>\n",
       "      <td>Sobig.F spreads when unsuspecting computer use...</td>\n",
       "      <td>The virus spreads when unsuspecting computer u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Quality    #1 ID    #2 ID  \\\n",
       "1634        0  2685984  2686122   \n",
       "1635        0   339215   339172   \n",
       "1636        0  2996850  2996734   \n",
       "1637        1  2095781  2095812   \n",
       "1638        1  2136244  2136052   \n",
       "\n",
       "                                              #1 String  \\\n",
       "1634  After Hughes refused to rehire Hernandez , he ...   \n",
       "1635  There are 103 Democrats in the Assembly and 47...   \n",
       "1636  Bethany Hamilton remained in stable condition ...   \n",
       "1637  Last week the power station ’ s US owners , AE...   \n",
       "1638  Sobig.F spreads when unsuspecting computer use...   \n",
       "\n",
       "                                              #2 String  \n",
       "1634  Hernandez filed an Equal Employment Opportunit...  \n",
       "1635  Democrats dominate the Assembly while Republic...  \n",
       "1636  Bethany , who remained in stable condition aft...  \n",
       "1637  The news comes after Drax 's American owner , ...  \n",
       "1638  The virus spreads when unsuspecting computer u...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/msr_paraphrase_test.tsv',sep='\\t',on_bad_lines='skip')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4858ce5c-e033-476f-a938-f4dcd76b32eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "获取 LLM 回答并更新预测:   0%|          | 0/1639 [00:00<?, ?it/s][W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::isin.Tensor_Tensor_out' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/usr/local/python3.10.13/lib/python3.10/site-packages/transformers/generation/logits_process.py:476: UserWarning: AutoNonVariableTypeMode is deprecated and will be removed in 1.10 release. For kernel implementations please use AutoDispatchBelowADInplaceOrView instead, If you are looking for a user facing API to enable running your inference-only workload, please use c10::InferenceMode. Using AutoDispatchBelowADInplaceOrView in user code is under risk of producing silent wrong result in some edge cases. See Note [AutoDispatchBelowAutograd] for more details. (Triggered internally at torch_npu/csrc/aten/common/TensorFactories.cpp:74.)\n",
      "  sorted_indices_to_remove[..., -self.min_tokens_to_keep :] = 0\n",
      "获取 LLM 回答并更新预测: 100%|██████████| 1639/1639 [07:12<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 定义调用 LLM 模型的函数\n",
    "def get_llm_response(row):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\":  f\"句子 1: {row['#1 String']}\\n句子 2: {row['#2 String']}\"}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to('npu')\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response\n",
    "\n",
    "response_records = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"获取 LLM 回答并更新预测\"):\n",
    "    id = row['#2 ID']\n",
    "    response = get_llm_response(row)\n",
    "    response_records.append({'ID': id, 'preQuality': response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdbd8466-b2dc-4015-9c44-0a976b252d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将更新后的记录写入文件\n",
    "output_file = './output/test_data_llm_predictions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ca11c37-1078-4df9-8a24-5119786a521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = pd.DataFrame(response_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e124decf-fc3c-48e2-b2e0-8957d16d11df",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639e9ce-6259-4453-a867-380656d16432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
